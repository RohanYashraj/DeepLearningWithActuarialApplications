{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Disclaimer\n",
                "This notebook was created for the SAV block course \"Deep Learning with Actuarial Applications in R\".\n",
                "\n",
                "The course is based on the publications on the following website: https://www.actuarialdatascience.org/\n",
                "\n",
                "Author: Daniel Meier\n",
                "\n",
                "# Applying Convolutional Neural Networks for classification of handwritten digits\n",
                "\n",
                "## Abstract\n",
                "The [MNIST dataset](http://yann.lecun.com/exdb/mnist/), i.e. images of handwriten digits to be recognized, is a standard dataset to illustrate the strengths of (deep) convolutional neural networks (CNNs). In this notebook we construct a 7-layer CNN (not counting the batch normalizations separately) with 3 pairs of a convolutional layer followed by max pooling, and a final fully connected layer with 10 outputs for each of the 10 digits.\n",
                "\n",
                "## Introduction\n",
                "The MNIST dataset consists of 70'000 monochrome pictures of pixel size 28 x 28 and is already split into a training set of 60'000 pictures and test set of 10'000 pictures.\n",
                "\n",
                "The constructed CNN is a 7-layer network comprising\n",
                "\n",
                "* a convolutional 2D layer: 10 filters of size 3 times 3 and stepsize 1 and 1,\n",
                "* a max pooling layer: window size 2 times 2, stepsize 2 and 2,\n",
                "* a convolutional 2D layer: 20 filters of size 3 times 3 and stepsize 1 and 1,\n",
                "* a max pooling layer: window size 2 times 2, stepsize 1 and 1,\n",
                "* a convolutional 2D layer: 40 filters of size 3 times 3 and stepsize 1 and 1,\n",
                "* a max pooling layer: window size 2 times 2, stepsize 2 and 2,\n",
                "* a fully connected layer.\n",
                "\n",
                "We formulate the problem as a classification problem minimizing the categorical crossentropy and consider the resulting multi-class accuracy as metric.\n",
                "\n",
                "In Section 0 we import all necessary modules and define the most relevant parameters. In Section 1 we load the MNIST dataset and plot some examples. Section 2 constructs the CNN and applies it on the MNIST dataset. Section 3 plots the accuracy history and the confusion matrix across all 10 digits, and Section 4 shows all wrongly classified images. Section 5 considers how translations, rotations, scalings affect model performance.\n",
                "\n",
                "## 0. Import modules, definition of parameters\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "options(encoding = 'UTF-8')\n",
                "\n",
                "# Loading all the necessary packages\n",
                "library(\"repr\")  # not needed in the Rmarkdown version, only for Jupyter notebook\n",
                "library(\"ggplot2\")\n",
                "library(\"keras\")\n",
                "library(\"tensorflow\")\n",
                "library(\"OpenImageR\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "knitr::opts_chunk$set(fig.width = 9, fig.height = 7)\n",
                "#options(repr.plot.width=4, repr.plot.height=10)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "validationRatio <- 0.15\n",
                "filterSize1     <- 3\n",
                "numberFilters1  <- 10\n",
                "filterSize2     <- 3\n",
                "numberFilters2  <- 20\n",
                "filterSize3     <- 3\n",
                "numberFilters3  <- 40\n",
                "numberEpochs    <- 10\n",
                "\n",
                "dataRoot <- \"../../data\"\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Loading the MNIST dataset\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "load_image_file <- function(filename) {\n",
                "  ret = list()\n",
                "  f = file(filename, 'rb')\n",
                "  readBin(f, 'integer', n = 1, size = 4, endian = 'big')\n",
                "  n    = readBin(f, 'integer', n = 1, size = 4, endian = 'big')\n",
                "  nrow = readBin(f, 'integer', n = 1, size = 4, endian = 'big')\n",
                "  ncol = readBin(f, 'integer', n = 1, size = 4, endian = 'big')\n",
                "  x = readBin(f, 'integer', n = n * nrow * ncol, size = 1, signed = FALSE)\n",
                "  close(f)\n",
                "  data.frame(matrix(x, ncol = nrow * ncol, byrow = TRUE))\n",
                "}\n",
                "\n",
                "load_label_file <- function(filename) {\n",
                "  f = file(filename, 'rb')\n",
                "  readBin(f, 'integer', n = 1, size = 4, endian = 'big')\n",
                "  n = readBin(f, 'integer', n = 1, size = 4, endian = 'big')\n",
                "  y = readBin(f, 'integer', n = n, size = 1, signed = FALSE)\n",
                "  close(f)\n",
                "  y\n",
                "}\n",
                "\n",
                "trainX <- load_image_file(file.path(dataRoot, \"cnn2\", \"train-images.idx3-ubyte\"))\n",
                "testX  <- load_image_file(file.path(dataRoot, \"cnn2\", \"t10k-images.idx3-ubyte\"))\n",
                "\n",
                "train_Y <- as.factor(load_label_file(file.path(dataRoot, \"cnn2\", \"train-labels.idx1-ubyte\")))\n",
                "test_Y  <- as.factor(load_label_file(file.path(dataRoot, \"cnn2\", \"t10k-labels.idx1-ubyte\")))\n",
                "\n",
                "trainX <- array_reshape(data.matrix(trainX) / 255, c(dim(trainX)[1], 28, 28, 1))\n",
                "testX <- array_reshape(data.matrix(testX) / 255, c(dim(testX)[1], 28, 28, 1))\n",
                "trainY <- to_categorical(train_Y, 10)\n",
                "testY <- to_categorical(test_Y, 10)\n",
                "\n",
                "par(mfrow = c(2, 4))\n",
                "for (j in 1:8) {\n",
                "    image(aperm(trainX[j, 28:1, , 1], c(2, 1)), col = gray(12:1 / 12))\n",
                "    title(train_Y[j])\n",
                "}\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Constructing and fitting the CNN\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "set.seed(0)\n",
                "tf$random$set_seed(0)\n",
                "\n",
                "cnn <- keras_model_sequential() %>%\n",
                "  layer_conv_2d(filters = numberFilters1, kernel_size = c(filterSize1, filterSize1),\n",
                "                strides = c(1,1), padding = 'valid', input_shape = c(28, 28, 1)) %>%\n",
                "  layer_batch_normalization() %>%\n",
                "  layer_activation('relu') %>%\n",
                "  layer_max_pooling_2d(pool_size = c(2,2), strides = c(2,2), padding = 'valid') %>%\n",
                "  \n",
                "  layer_conv_2d(filters = numberFilters2, kernel_size = c(filterSize2, filterSize2),\n",
                "                strides = c(1,1), padding = 'valid') %>%\n",
                "  layer_batch_normalization() %>%\n",
                "  layer_activation('relu') %>%\n",
                "  layer_max_pooling_2d(pool_size = c(2,2), strides = c(1,1), padding = 'valid') %>%\n",
                "  \n",
                "  layer_conv_2d(filters = numberFilters3, kernel_size = c(filterSize3, filterSize3),\n",
                "                strides = c(1,1), padding = 'valid') %>%\n",
                "  layer_batch_normalization() %>%\n",
                "  layer_activation('relu') %>%\n",
                "  layer_max_pooling_2d(pool_size = c(2,2), strides = c(2,2)) %>%\n",
                "  \n",
                "  layer_flatten() %>%\n",
                "  layer_dense(10) %>%\n",
                "  layer_activation('softmax', name = 'softmax') %>%\n",
                "  compile(loss = loss_categorical_crossentropy, optimizer = optimizer_adadelta(), metrics = c('accuracy'))\n",
                "\n",
                "# RSc: below took ~22 minutes with 1CPU / 8GB / 40 epochs\n",
                "summary <- cnn %>% fit(\n",
                "  x = trainX,\n",
                "  y = trainY,\n",
                "  epochs = numberEpochs,\n",
                "  validation_split = validationRatio,\n",
                "  batch_size = 64,\n",
                "  verbose = 1\n",
                ")\n",
                "summary(cnn)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Accuracy history and confusion matrix\n",
                "\n",
                "**Exercise:** Experiment with other structures/parameters of the CNN. Make use of summary(cnn) to check the dimensions of inputs/outputs of each layer. How are the dimensions affected by strides, padding, kernel_size, number of filters?\n",
                "\n",
                "**Exercise:** Change the random seeds (`set.seed(0)` and `tf$random$set_seed(0)`). If you keep the random seeds, are the results 100% reproducible?\n",
                "\n",
                "**Exercise:** Change the relu activation functions to some other activation functions.\n",
                "\n",
                "**Exercise:** The input images are gray scale images. Turn them into black-white images (only allowing values 0 and 1) and refit the model.\n",
                "\n",
                "**Exercise:** Introduce some random noise in the images, e.g. by adding i.i. uniformly distributed numbers out of the interval [-r,r]. Plot r vs accuracy for some selected r.\n",
                "\n",
                "**Exercise:** Set 0<r<28^2 random pixels to white and plot r vs accuracy for some selected r.\n",
                "\n",
                "**Exercise:** There are several other structures/parameters to be found in the web, e.g. https://keras.rstudio.com/articles/examples/mnist_cnn.html, or https://tensorflow.rstudio.com/guide/keras/, etc. not all of them necessarily make use of convolutional layers. What are the main differences between these structures? Advantages/disadvantages? Which performs best?\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot(summary)\n",
                "print(summary)\n",
                "\n",
                "#testP <- cnn %>% predict_classes(testX)  # This is deprecated in keras/tf 2.6. In our case, below is applicable instead.\n",
                "testP <- cnn %>% predict(testX) %>% k_argmax()\n",
                "testP <- as.array(testP)\n",
                "\n",
                "confusion_matrix <- as.data.frame(table(testP, test_Y))\n",
                "\n",
                "ggplot(data = confusion_matrix, aes(x = testP, y = test_Y)) +\n",
                "  geom_tile(aes(fill = Freq)) +\n",
                "  geom_text(aes(label = sprintf(\"%1.0f\", Freq)), vjust = 1) +\n",
                "  scale_fill_gradient(low = \"white\", high = \"blue\", trans = \"log\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Wrongly classified images\n",
                "Images where the actual image differs from the predicted image (denoted as A and P) are shown in this section.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "incorrectIdx <- which(test_Y != testP)\n",
                "par(mfrow = c(2, 4))\n",
                "for (j in 1:8) {\n",
                "    image(aperm(testX[incorrectIdx[j], 28:1, , 1], c(2,1)), col = gray(12:1 / 12))\n",
                "    title(paste0('A: ', test_Y[incorrectIdx[j]], ', P:', testP[incorrectIdx[j]]))\n",
                "}\n",
                "\n",
                "print(paste(length(incorrectIdx), \"incorrectly classified digits (out of 10'000 digits)\"))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Rotations, translations, scalings\n",
                "\n",
                "The following 3 cells (chunks) rotate, translate and scale images. Observe how the model predictions (the softmax layer) are impacted by these transformations.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "layerModel <- keras_model(input = cnn$input, outputs = get_layer(cnn, 'softmax')$output)  # the softmax activation layer\n",
                "img <- trainX[19, 28:1, , ]\n",
                "par(mfrow = c(2, 4))\n",
                "for (j in seq(0, 315, 45)) {\n",
                "    image(aperm(rotateImage(img, j), c(2,1)), col = gray(12:1 / 12))\n",
                "    title(j)\n",
                "}\n",
                "\n",
                "activationSoftMax <- matrix(0, 360, 10)\n",
                "for (j in 1:360) {\n",
                "    imgRotated <- img\n",
                "    imgRotated <- rotateImage(img, j)[28:1, ]\n",
                "    activationSoftMax[j, ] <- layerModel %>% predict(array_reshape(imgRotated, c(1, 28, 28, 1)))\n",
                "}\n",
                "\n",
                "par(mfrow = c(1, 1))\n",
                "plot(1:360, activationSoftMax[, 7], type = \"l\", col = \"blue\", xlab = \"Rotation angle\", ylab = \"Output of softmax layer\")\n",
                "lines(1:360, activationSoftMax[, 10], col = \"red\")\n",
                "lines(1:360, activationSoftMax[, 9], col = \"orange\")\n",
                "lines(1:360, activationSoftMax[, 6], col = \"magenta\")\n",
                "legend(\"topright\", legend = c(\"7\", \"10\", \"9\", \"6\"), fill = c(\"blue\", \"red\", \"orange\", \"magenta\"))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "activationSoftMax <- array(0, c(121, 10, 18))\n",
                "par(mfrow = c(3, 6))\n",
                "for (i in 1:18) {\n",
                "    img <- trainX[i, , , ]\n",
                "    for (j in 1:121) {\n",
                "        shiftRows <- j %% 11 - 5\n",
                "        shiftCols <- floor(j / 11) - 5\n",
                "        if (shiftRows != 0 && shiftCols != 0)\n",
                "          imgShifted <- translation(img, shift_rows = shiftRows, shift_cols = shiftCols)\n",
                "        else\n",
                "          imgShifted <- img\n",
                "        activationSoftMax[j, , i] <- layerModel %>% predict(array_reshape(imgShifted, c(1, 28, 28, 1)))\n",
                "        if (j == 1) {\n",
                "            lowerRight <- imgShifted\n",
                "        }\n",
                "    }\n",
                "    image(aperm(lowerRight[28:1, ], c(2, 1)), col = gray(12:1 / 12))\n",
                "}\n",
                "par(mfrow = c(3, 6))\n",
                "for (i in 1:18) {\n",
                "    image(array_reshape(activationSoftMax[, as.numeric(train_Y[i]), i], c(11, 11)), col = gray(12:1 / 12))\n",
                "}\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "activationSoftMax <- array(0, c(121, 10, 18))\n",
                "par(mfrow = c(3, 6))\n",
                "for (i in 1:18) {\n",
                "    img <- trainX[i, , , ]\n",
                "    for (j in 1:121) {\n",
                "        imgZoomed <- cropImage(\n",
                "          resizeImage(img, height = round(28*((j%%11)/20+1)), width = round(28*((floor(j/11))/20+1)), method = \"bilinear\"),\n",
                "          new_height = 1:28,\n",
                "          new_width = 1:28,\n",
                "          type = \"user_defined\"\n",
                "        )\n",
                "        activationSoftMax[j, , i] <- layerModel %>% predict(array_reshape(imgZoomed, c(1, 28, 28, 1)))\n",
                "        if (j == 48) {\n",
                "            selectedImgZoom <- imgZoomed\n",
                "        }\n",
                "    }\n",
                "    image(aperm(selectedImgZoom[28:1, ], c(2, 1)), col = gray(12:1 / 12))\n",
                "}\n",
                "par(mfrow = c(3, 6))\n",
                "for (i in 1:18) {\n",
                "    image(array_reshape(activationSoftMax[, as.numeric(train_Y[i]), i], c(11, 11)), col = gray(12:1 / 12))\n",
                "}\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
